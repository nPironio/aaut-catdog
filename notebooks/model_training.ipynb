{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr = \"char\"\n",
    "\n",
    "# Tengo GPU pero no cuda compatible, me rompe cuando intento correr con GPU\n",
    "if usr == \"nico\":\n",
    "    device=\"cpu\"\n",
    "    num_workers = 4\n",
    "    \n",
    "if usr == \"char\":\n",
    "    num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catdog.dataset import CatDogDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train set with length 2948\n",
      "Loaded test set with length 738\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torchvision.transforms as tvt\n",
    "\n",
    "from catdog.utils.image import BBoxIdentityWrapper, RandomHorizontalFlipBBox, RandomVerticalFlipBBox\n",
    "\n",
    "\n",
    "identity_transforms = [\n",
    "    tvt.RandomGrayscale(),\n",
    "    tvt.ColorJitter(brightness=10, contrast=10, saturation=10, hue=[-0.5, 0.5]),\n",
    "    tvt.RandomInvert(p=.1),\n",
    "    tvt.RandomPosterize(bits=7, p=.1), # keeps 7 bits for each channel\n",
    "    tvt.RandomAutocontrast(p=.1),\n",
    "    #tvt.RandomAdjustSharpness(sharpness_factor=1.25, p=0.1),  # sharpens\n",
    "    #tvt.RandomAdjustSharpness(sharpness_factor=.75, p=0.1),  # blurs\n",
    "    #tvt.RandomSolarize(threshold=250, p=0.1),\n",
    "    #tvt.RandomEqualize(p=0.1)\n",
    "]\n",
    "wrapped_identity_transforms = [BBoxIdentityWrapper(t) for t in identity_transforms]\n",
    "flipper_transforms = [RandomHorizontalFlipBBox(), RandomVerticalFlipBBox()]\n",
    "\n",
    "\n",
    "# fisura way to use tvt.Compose on (img, bbox) pairs\n",
    "class BBoxCompose(tvt.Compose):\n",
    "    \n",
    "    calls = 0\n",
    "    \n",
    "    def __call__(self, img, bbox):\n",
    "        BBoxCompose.calls += 1\n",
    "        try:\n",
    "            if BBoxCompose.calls == 3:\n",
    "                # import ipdb; ipdb.set_trace()\n",
    "                pass\n",
    "            for t in self.transforms:\n",
    "                img, bbox = t(img, bbox)\n",
    "        except TypeError as e:\n",
    "            print(e)\n",
    "            import ipdb; ipdb.set_trace()\n",
    "            pass\n",
    "        return img, bbox\n",
    "\n",
    "# composed_transforms = BBoxCompose(wrapped_identity_transforms + flipper_transforms)\n",
    "# composed_transforms = BBoxCompose(flipper_transforms)\n",
    "composed_transforms = BBoxCompose(flipper_transforms)\n",
    "\n",
    "train_set_pd = pd.read_csv(DATA_DIR + 'train.csv')\n",
    "train_set_torch = CatDogDataset(train_set_pd, transformations=composed_transforms)\n",
    "print(f\"Loaded train set with length {len(train_set_torch)}\")\n",
    "\n",
    "test_set_pd = pd.read_csv(DATA_DIR + 'test.csv')\n",
    "test_set_torch = CatDogDataset(test_set_pd)\n",
    "print(f\"Loaded test set with length {len(test_set_torch)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 82\n",
    "train_loader = torch.utils.data.DataLoader(train_set_torch, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_set_torch, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "seed = 142\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test image\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "test_img_path = DATA_DIR + 'images/' + cat_dog_df[\"file\"].iloc[0]\n",
    "test_img = Image.open(test_img_path).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConvolutionalClassifier(\n",
       "  (AUROC): AUROC()\n",
       "  (Precision): Precision()\n",
       "  (Recall): Recall()\n",
       "  (model): Sequential(\n",
       "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (relu1): ReLU()\n",
       "    (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (batch_norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (relu2): ReLU()\n",
       "    (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (batch_norm_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (relu3): ReLU()\n",
       "    (pool3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (batch_norm_3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (output): CatDogOutput(\n",
       "      (classify_layer): Linear(in_features=460800, out_features=1, bias=True)\n",
       "      (bbox_layer): Linear(in_features=460800, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catdog.models.feedforward import MLPClassifier\n",
    "from catdog.models.convolutional import ConvolutionalClassifier\n",
    "\n",
    "\n",
    "# model_kwargs = {'input_size': 500*500*3, 'hidden_sizes': (500, 350, 256, 128, 50, 10)}\n",
    "# model = MLPClassifier(**model_kwargs)\n",
    "\n",
    "lr_str = '2e-4' \n",
    "dropout_p = 0\n",
    "model_kwargs = {\n",
    "    'input_shape': (3, 500, 500), \n",
    "    'dropout_p': dropout_p, \n",
    "    'optimizer_params':{'lr': float(lr_str)}\n",
    "}\n",
    "model = ConvolutionalClassifier(**model_kwargs)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 142\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_classifier_3_layers_with_max_pooling_all_transforms_batch_norm_batch_size_82_lr_2e-4\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "seed_everything(142, workers=True)\n",
    "\n",
    "if dropout_p:\n",
    "    reg = f'dropout_{dropout_p}_'\n",
    "else:\n",
    "    reg = 'batch_norm_'\n",
    "\n",
    "exp_name = f'CNN_classifier_3_layers_with_max_pooling_all_transforms_{reg}batch_size_{batch_size}_lr_{lr_str}'\n",
    "print(exp_name)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='./lightning_checkpoints/',\n",
    "    filename=exp_name,\n",
    "    mode='min',\n",
    "    save_top_k=3\n",
    ")\n",
    "\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=exp_name)\n",
    "\n",
    "trainer = Trainer(gpus=int(device=='cuda'), # hacky way to say 0 or 1 \n",
    "                  max_epochs=30,\n",
    "                  logger=logger,\n",
    "                  callbacks=[EarlyStopping(monitor=\"val_loss\", patience=6, mode='min'),\n",
    "                             checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/usr/local/lib/python3.6/dist-packages/OpenSSL/crypto.py:8: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.\n",
      "  from cryptography import utils, x509\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | AUROC     | AUROC      | 0     \n",
      "1 | Precision | Precision  | 0     \n",
      "2 | Recall    | Recall     | 0     \n",
      "3 | model     | Sequential | 2.4 M \n",
      "-----------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.591     Total estimated model params size (MB)\n",
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /alloc/data/fury_fda-fraud-evasion-off/notebooks/lightning_checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n",
      "/usr/local/lib/python3.6/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Global seed set to 142\n",
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n",
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/data_loading.py:433: UserWarning: The number of training samples (36) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  f\"The number of training samples ({self.num_training_batches}) is smaller than the logging interval\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb54229f7d874afeacaa8d0938802328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object is not iterable\n",
      "> \u001b[0;32m<ipython-input-9-dfeffc0812a7>\u001b[0m(38)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     37 \u001b[0;31m            \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 38 \u001b[0;31m            \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     39 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  BBoxCompose.calls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object is not iterable\n",
      "> \u001b[0;32m<ipython-input-9-dfeffc0812a7>\u001b[0m(38)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     37 \u001b[0;31m            \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 38 \u001b[0;31m            \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     39 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object is not iterable\n",
      "> \u001b[0;32m<ipython-input-9-dfeffc0812a7>\u001b[0m(38)\u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     37 \u001b[0;31m            \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 38 \u001b[0;31m            \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     39 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "### Train and eval model\n",
    "\n",
    "trainer.fit(model, train_loader, test_loader)  # here we are using test set as validation set\n",
    "trainer.test(ckpt_path=\"best\", dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval previously trained model\n",
    "\n",
    "checkpoint_callback.best_model_path = '/alloc/data/fury_fda-fraud-evasion-off/notebooks/lightning_checkpoints/test_model_training-v8.ckpt'\n",
    "\n",
    "best_model = model.load_from_checkpoint(checkpoint_callback.best_model_path, **model_kwargs).to(device)\n",
    "trainer.test(model=best_model, dataloaders=test_loader, verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
