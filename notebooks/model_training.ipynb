{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr = \"char\"\n",
    "\n",
    "# Tengo GPU pero no cuda compatible, me rompe cuando intento correr con GPU\n",
    "if usr == \"nico\":\n",
    "    device=\"cpu\"\n",
    "    num_workers = 4\n",
    "    \n",
    "if usr == \"char\":\n",
    "    num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catdog.dataset import CatDogDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train set with length 2948\n",
      "Loaded test set with length 738\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "train_set_pd = pd.read_csv(DATA_DIR + 'train.csv')\n",
    "train_set_torch = CatDogDataset(train_set_pd)\n",
    "print(f\"Loaded train set with length {len(train_set_torch)}\")\n",
    "\n",
    "test_set_pd = pd.read_csv(DATA_DIR + 'test.csv')\n",
    "test_set_torch = CatDogDataset(test_set_pd)\n",
    "print(f\"Loaded test set with length {len(test_set_torch)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(train_set_torch, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_set_torch, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "seed = 142\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test image\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "test_img_path = DATA_DIR + 'images/' + cat_dog_df[\"file\"].iloc[0]\n",
    "test_img = Image.open(test_img_path).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(\n",
       "  (AUROC): AUROC()\n",
       "  (Precision): Precision()\n",
       "  (Recall): Recall()\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=750000, out_features=50, bias=True)\n",
       "    (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=50, out_features=10, bias=True)\n",
       "    (4): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): CatDogOutput(\n",
       "      (classify_layer): Linear(in_features=10, out_features=1, bias=True)\n",
       "      (bbox_layer): Linear(in_features=10, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catdog.models.feedforward import MLPClassifier\n",
    "\n",
    "model_kwargs = {'input_size': 500*500*3, 'hidden_sizes': (50, 10)}\n",
    "model = MLPClassifier(**model_kwargs)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 142\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "seed_everything(142, workers=True)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='./lightning_checkpoints/',\n",
    "    filename='test_model_training',\n",
    "    mode='min',\n",
    "    save_top_k=3\n",
    ")\n",
    "\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=\"MLP_classifier\")\n",
    "\n",
    "trainer = Trainer(gpus=int(device=='cuda'), # hacky way to say 0 or 1 \n",
    "                  max_epochs=1,\n",
    "                  logger=logger,\n",
    "                  callbacks=[EarlyStopping(monitor=\"val_loss\", patience=15, mode='min'),\n",
    "                             checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/usr/local/lib/python3.6/dist-packages/OpenSSL/crypto.py:8: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography and will be removed in a future release.\n",
      "  from cryptography import utils, x509\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | AUROC     | AUROC      | 0     \n",
      "1 | Precision | Precision  | 0     \n",
      "2 | Recall    | Recall     | 0     \n",
      "3 | model     | Sequential | 37.5 M\n",
      "-----------------------------------------\n",
      "37.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "37.5 M    Total params\n",
      "150.003   Total estimated model params size (MB)\n",
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:631: UserWarning: Checkpoint directory /alloc/data/fury_fda-fraud-evasion-off/notebooks/lightning_checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n",
      "/usr/local/lib/python3.6/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Global seed set to 142\n",
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05085e3d5b014beb9cabc138ef7f18e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Restoring states from the checkpoint path at /alloc/data/fury_fda-fraud-evasion-off/notebooks/lightning_checkpoints/test_model_training-v3.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /alloc/data/fury_fda-fraud-evasion-off/notebooks/lightning_checkpoints/test_model_training-v3.ckpt\n",
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b824322f05b49528c684efa27f2015b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_auroc': 0.027530431747436523,\n",
      " 'test_bbox_loss': 0.021727534011006355,\n",
      " 'test_classification_loss': 0.631763219833374,\n",
      " 'test_loss': 0.6483300055066744,\n",
      " 'test_precision': 0.0,\n",
      " 'test_recall': 0.0}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_precision': 0.0,\n",
       "  'test_recall': 0.0,\n",
       "  'test_auroc': 0.027530431747436523,\n",
       "  'test_classification_loss': 0.631763219833374,\n",
       "  'test_bbox_loss': 0.021727534011006355,\n",
       "  'test_loss': 0.6483300055066744}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Train and eval model\n",
    "\n",
    "trainer.fit(model, train_loader, test_loader)  # here we are using test set as validation set\n",
    "trainer.test(ckpt_path=\"best\", dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Eval previously trained model\n",
    "\n",
    "checkpoint_callback.best_model_path = '/alloc/data/fury_fda-fraud-evasion-off/notebooks/lightning_checkpoints/test_model_training-v8.ckpt'\n",
    "\n",
    "best_model = model.load_from_checkpoint(checkpoint_callback.best_model_path, **model_kwargs).to(device)\n",
    "trainer.test(model=best_model, dataloaders=test_loader, verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
